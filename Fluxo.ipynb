{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instalação das bibliotecas necessárias para execução do código\r\n",
    "!pip install pandas\r\n",
    "!pip install numpy\r\n",
    "!pip install io\r\n",
    "!pip install zipfile\r\n",
    "!pip install requests\r\n",
    "!pip install sqlalchemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from io import BytesIO\r\n",
    "from zipfile import ZipFile\r\n",
    "import requests\r\n",
    "import sqlalchemy\r\n",
    "\r\n",
    "user = 'root'\r\n",
    "password = '12345678'\r\n",
    "\r\n",
    "my_conn=sqlalchemy.create_engine(f\"mysql+mysqldb://{user}:{password}@localhost\")\r\n",
    "\r\n",
    "save_sql = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que baixa os arquivos necessários\r\n",
    "def download_and_unzip(url, extract_to='.'):\r\n",
    "    http_response = requests.get(url).content\r\n",
    "    zipfile = ZipFile(BytesIO(http_response))\r\n",
    "    zipfile.extractall(path=extract_to)\r\n",
    "\r\n",
    "def download(url, extract_to='.'):\r\n",
    "    http_response = requests.get(url).content\r\n",
    "    open(extract_to, 'wb').write(http_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download e salvamento dos dados do enade, e dados para criação das tabelas\r\n",
    "download_and_unzip(f'https://download.inep.gov.br/microdados/Enade_Microdados/microdados_Enade_2017_portal_2018.10.09.zip', extract_to='DATA/2017')\r\n",
    "download(f'https://download.inep.gov.br/educacao_superior/igc_cpc/2018/resultado_cpc_2017.xlsx', extract_to='DATA/2017/resultados_cpc_2017.xlsx')\r\n",
    "\r\n",
    "download_and_unzip(f'https://download.inep.gov.br/microdados/Enade_Microdados/microdados_enade_2018.zip', extract_to='DATA')\r\n",
    "download(f'https://download.inep.gov.br/educacao_superior/igc_cpc/2018/portal_CPC_edicao2018.xlsx', extract_to='DATA/2018/resultados_cpc_2018.xlsx')\r\n",
    "\r\n",
    "download_and_unzip(f'https://download.inep.gov.br/microdados/Enade_Microdados/microdados_enade_2019.zip', extract_to='DATA/2019')\r\n",
    "download(f'https://download.inep.gov.br/educacao_superior/indicadores/resultados/2019/resultados_cpc_2019.xlsx', extract_to='DATA/2019/resultados_cpc_2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (29,31,32,44,45,46,47,54,55,56) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\Users\\danie\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (48,49,50,51,52,53,57,58,59,84,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#Não precisa ser executado caso os dados ja tenham sido coletados uma vez\r\n",
    "#coleta e concatena todos os  \"csv\"s da pasta \"dados\"\r\n",
    "df2017 = pd.read_csv(f'DATA/2017/3.DADOS/MICRODADOS_ENADE_2017.txt',delimiter=';')\r\n",
    "df2018 = pd.read_csv(f'DATA/2018/3.DADOS/microdados_enade_2018.txt',delimiter=';')\r\n",
    "df2019 = pd.read_csv(f'DATA/2019/3.DADOS/microdados_enade_2019.txt',delimiter=';')\r\n",
    "\r\n",
    "#tratamentos para igualar a codificação dos dados\r\n",
    "df2018['CO_MODALIDADE'] = df2018['CO_MODALIDADE'] - 1\r\n",
    "\r\n",
    "data = pd.concat([df2017,df2018,df2019])\r\n",
    "\r\n",
    "data['CO_CATEGAD'] = data['CO_CATEGAD'].replace([[93,10002],[115,10001],[116,10003],[118,10005,10006],[120,121,17634,10007,10008,10009],[895]],[1,2,3,4,5,7])\r\n",
    "\r\n",
    "#coleta somente as colunas de interesse\r\n",
    "data = data.reset_index()[['NU_ANO','CO_IES','CO_MUNIC_CURSO','CO_CURSO','CO_GRUPO','CO_MODALIDADE','CO_TURNO_GRADUACAO','CO_CATEGAD','index','TP_PRES','TP_PR_GER','TP_PR_OB_FG','TP_PR_DI_FG','TP_PR_OB_CE','TP_PR_DI_CE','NT_GER','NT_FG','NT_OBJ_FG','NT_DIS_FG','NT_CE','NT_OBJ_CE','NT_DIS_CE','CO_RS_I1','CO_RS_I2','CO_RS_I3','CO_RS_I4','CO_RS_I5','CO_RS_I6','CO_RS_I7','CO_RS_I8','CO_RS_I9','NU_IDADE','TP_SEXO','ANO_FIM_EM','ANO_IN_GRAD']]\r\n",
    "\r\n",
    "#tratamento para modificar o tipo dos dados\r\n",
    "for column in data.columns:\r\n",
    "    if 'NT' in column:\r\n",
    "        data[column] = data[column].str.replace(' ','0')\r\n",
    "        data[column] = data[column].str.replace(',','.').astype(float)\r\n",
    "\r\n",
    "#salva os dados no arquivo data.csv\r\n",
    "data.to_csv('data.csv')\r\n",
    "\r\n",
    "#coleta os dados auxiliares dastabelas de dados\r\n",
    "df2017_aux = pd.read_excel(f'DATA/2017/resultados_cpc_2017.xlsx')\r\n",
    "df2018_aux = pd.read_excel(f'DATA/2018/resultados_cpc_2018.xlsx')\r\n",
    "df2019_aux = pd.read_excel(f'DATA/2019/resultados_cpc_2019.xlsx')\r\n",
    "\r\n",
    "data_aux = pd.concat([df2017_aux,df2018_aux,df2019_aux])\r\n",
    "\r\n",
    "#retira as colunas de interesse e trata os nomes das mesmas\r\n",
    "data_aux = data_aux[['Código da Área', 'Área de Avaliação', 'Código da IES', 'Nome da IES', 'Código do Curso', 'Município do Curso']].drop_duplicates()\r\n",
    "data_aux.columns = ['CO_GRUPO', 'NM_GRUPO', 'CO_IES', 'NM_IES', 'CO_CURSO', 'NM_MUNIC_CURSO']\r\n",
    "\r\n",
    "#salva os dados auxiliares\r\n",
    "data_aux.to_csv('data_aux.csv')\r\n",
    "\r\n",
    "#coleta os dados auxiliares dastabelas de dados\r\n",
    "df2017_aux = pd.read_excel(f'DATA/2017/resultados_cpc_2017.xlsx')\r\n",
    "df2018_aux = pd.read_excel(f'DATA/2018/resultados_cpc_2018.xlsx')\r\n",
    "df2019_aux = pd.read_excel(f'DATA/2019/resultados_cpc_2019.xlsx')\r\n",
    "\r\n",
    "data_aux = pd.concat([df2017_aux,df2018_aux,df2019_aux])\r\n",
    "\r\n",
    "#retira as colunas de interesse e trata os nomes das mesmas\r\n",
    "data_aux = data_aux[['Código da Área', 'Área de Avaliação', 'Código da IES', 'Nome da IES', 'Código do Curso', 'Município do Curso']].drop_duplicates()\r\n",
    "data_aux.columns = ['CO_GRUPO', 'NM_GRUPO', 'CO_IES', 'NM_IES', 'CO_CURSO', 'NM_MUNIC_CURSO']\r\n",
    "data_aux['NM_CURSO'] = data_aux['NM_GRUPO'] + data_aux['NM_IES'] + data_aux['NM_MUNIC_CURSO']\r\n",
    "\r\n",
    "#salva os dados auxiliares\r\n",
    "data_aux.to_csv('data_aux.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRIAR TABELAS PARA POPULAR O BD\r\n",
    "\r\n",
    "#Lê os dados do arquivo data.csv\r\n",
    "data = pd.read_csv('data.csv')\r\n",
    "data_aux = pd.read_csv('data_aux.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-8fbf71c3c191>:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tabela['CO_CURSO'] = np.where(df_tabela['CO_CURSO'].isin(df_curso['CO_CURSO']), df_tabela['CO_CURSO'], None)\n",
      "<ipython-input-21-8fbf71c3c191>:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tabela['CO_IES'] = np.where(df_tabela['CO_IES'].isin(df_organizacao['CO_IES']), df_tabela['CO_IES'], None)\n",
      "<ipython-input-21-8fbf71c3c191>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tabela[f'CO_RS_I{i}'] = df_tabela[f'CO_RS_I{i}'].fillna(' ')\n"
     ]
    }
   ],
   "source": [
    "#DEFININDO TABELA MODALIDADE\r\n",
    "df_modalidade = pd.DataFrame(data={'CO_MODALIDADE': [0,1], 'NM_MODALIDADE': ['EaD','Presencial']})\r\n",
    "df_modalidade.to_csv('tabelas/modalidade.csv')\r\n",
    "\r\n",
    "#DEFININDO TABELA CATEGORIA\r\n",
    "df_categoria = pd.DataFrame(data={'CO_CATEGAD': [1,2,3,4,5,7], 'NM_CATEGAD': ['Pública Federal','Pública Estadual','Pública Municipal','Privada com fins lucrativos','Privada sem fins lucrativos','Especial']})\r\n",
    "df_categoria.to_csv('tabelas/categoria.csv')\r\n",
    "\r\n",
    "#DEFININDO TABELA TURNO\r\n",
    "df_turno = pd.DataFrame(data={'CO_TURNO_GRADUACAO': [1,2,3,4], 'NM_TURNO_GRADUACAO': ['Matutino','Vespertino','Integral','Noturno']})\r\n",
    "df_turno.to_csv('tabelas/turno.csv')\r\n",
    "\r\n",
    "#DEFININDO TABELA PRESENCA\r\n",
    "df_presenca = pd.DataFrame(data={'CO_PRESENCA': [222,333,334,444,555,556,888,889,999], 'NM_PRESENCA': ['Ausente','Inscrição indevida/Em Branco','Participação indevida','Dupla Graduação','Válido','Desconsiderado pela Aplicadora','desconsiderado pelo INEP','Ação Judicial','Ação Judicial']})\r\n",
    "df_presenca.to_csv('tabelas/presenca.csv')\r\n",
    "\r\n",
    "#DEFININDO TABELA QUESTIONARIO\r\n",
    "df_questionario = pd.DataFrame(data={'CO_QUEST': ['A','B','C','D','E','*','.','valor em branco',' '], 'NM_QUEST': ['Muito Fácil','Fácil','Médio','Difícil','Muito Difícil','Resposta anulada', 'Sem resposta','Resposta não válida','Resposta não válida']})\r\n",
    "df_questionario.to_csv('tabelas/questionario.csv')\r\n",
    "\r\n",
    "#DEFININDO TABELA GRUPO\r\n",
    "df_grupo = data_aux[['CO_GRUPO','NM_GRUPO']].drop_duplicates(['CO_GRUPO']).dropna()\r\n",
    "df_grupo.to_csv('tabelas/grupo.csv')\r\n",
    "\r\n",
    "#DEFININDO TABELA CURSO\r\n",
    "df_curso = data_aux[['CO_CURSO','NM_CURSO']].drop_duplicates(['CO_CURSO']).dropna()\r\n",
    "df_curso.to_csv('tabelas/curso.csv')\r\n",
    "\r\n",
    "#DEFININDO TABELA ORGANIZACAO\r\n",
    "df_organizacao = data_aux[['CO_IES','NM_IES']].drop_duplicates(['CO_IES']).dropna()\r\n",
    "df_organizacao.to_csv('tabelas/organizacao.csv')\r\n",
    "\r\n",
    "#DEFININDO TABELA MUNICIPIO\r\n",
    "df_regiao = pd.DataFrame(data={\r\n",
    "    'NM_UF': ['AC', 'AL', 'AM', 'AP', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MG', 'MS', 'MT', 'PA', 'PB', 'PE', 'PI', 'PR', 'RJ', 'RN', 'RO', 'RR', 'RS', 'SC', 'SE', 'SP', 'TO'],\r\n",
    "    'NM_REGIAO': ['NORTE', 'NORDESTE', 'NORTE', 'NORTE','NORDESTE','NORDESTE','CENTRO-OESTE', 'SUDESTE','CENTRO-OESTE','NORDESTE','SUDESTE','CENTRO-OESTE','CENTRO-OESTE','NORTE','NORDESTE','NORDESTE','NORDESTE','SUL','SUDESTE','NORDESTE','NORTE','NORTE','SUL','SUL','NORDESTE','SUDESTE','NORTE']\r\n",
    "})\r\n",
    "df_municipio = pd.read_excel('DATA/2019/1.LEIA-ME/Dicionário de variáveis dos Microdados do Enade 2019.xlsx',sheet_name='MUNICÍPIOS', header=3)\r\n",
    "df_municipio = df_municipio[['CÓDIGO DO MUNICÍPIO','NOME DO MUNICÍPIO','UF']]\r\n",
    "df_municipio.columns = ['CO_MUNIC_CURSO','NM_MUNICIPIO','NM_UF']\r\n",
    "df_municipio = df_municipio.merge(df_regiao, on='NM_UF')\r\n",
    "df_municipio.to_csv('tabelas/municipio.csv')\r\n",
    "\r\n",
    "#DEFININDO TABELA ALUNO\r\n",
    "data = data.reset_index().rename(columns={'index': 'CO_ALUNO'})\r\n",
    "df_aluno = data[['CO_ALUNO','NU_IDADE','TP_SEXO','ANO_FIM_EM','ANO_IN_GRAD']].drop_duplicates(['CO_ALUNO'])\r\n",
    "df_aluno.to_csv('tabelas/aluno.csv')\r\n",
    "\r\n",
    "#DEFININDO TABELA PRINCIPAL\r\n",
    "df_notas = data[['NU_ANO','CO_IES','CO_MUNIC_CURSO','CO_CURSO','CO_GRUPO','CO_MODALIDADE','CO_TURNO_GRADUACAO','CO_CATEGAD','CO_ALUNO','TP_PRES','TP_PR_GER','TP_PR_OB_FG','TP_PR_DI_FG','TP_PR_OB_CE','TP_PR_DI_CE','NT_GER','NT_FG','NT_OBJ_FG','NT_DIS_FG','NT_CE','NT_OBJ_CE','NT_DIS_CE','CO_RS_I1','CO_RS_I2','CO_RS_I3','CO_RS_I4','CO_RS_I5','CO_RS_I6','CO_RS_I7','CO_RS_I8','CO_RS_I9']]\r\n",
    "df_notas['CO_CURSO'] = np.where(df_notas['CO_CURSO'].isin(df_curso['CO_CURSO']), df_notas['CO_CURSO'], None)\r\n",
    "df_notas['CO_IES'] = np.where(df_notas['CO_IES'].isin(df_organizacao['CO_IES']), df_notas['CO_IES'], None)\r\n",
    "for i in range(1,10):\r\n",
    "    df_notas[f'CO_RS_I{i}'] = df_notas[f'CO_RS_I{i}'].fillna(' ')\r\n",
    "df_notas.to_csv('tabelas/notas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_sql:\r\n",
    "    #CRIA O BANCO DE DADOS DESDE O DATABASE\r\n",
    "    file = open('script_bd.sql')\r\n",
    "    escaped_sql = sqlalchemy.text(file.read())\r\n",
    "    my_conn.execute(escaped_sql)\r\n",
    "\r\n",
    "    my_conn=sqlalchemy.create_engine(f\"mysql+mysqldb://{user}:{password}@localhost/enade\")\r\n",
    "\r\n",
    "    df_modalidade.to_sql(con=my_conn,name='modalidade',if_exists='append',index=False)\r\n",
    "    df_categoria.to_sql(con=my_conn,name='categoria',if_exists='append',index=False)\r\n",
    "    df_presenca.to_sql(con=my_conn,name='presenca',if_exists='append',index=False)\r\n",
    "    df_questionario.to_sql(con=my_conn,name='questionario',if_exists='append',index=False)\r\n",
    "    df_grupo.to_sql(con=my_conn,name='grupo',if_exists='append',index=False)\r\n",
    "    df_curso.to_sql(con=my_conn,name='curso',if_exists='append',index=False)\r\n",
    "    df_organizacao.to_sql(con=my_conn,name='organizacao',if_exists='append',index=False)\r\n",
    "    df_municipio.to_sql(con=my_conn,name='municipio',if_exists='append',index=False)\r\n",
    "    df_aluno.to_sql(con=my_conn,name='aluno',if_exists='append',index=False)\r\n",
    "    df_notas.to_sql(con=my_conn,name='notas',if_exists='append',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c24dc9a87ddf819fb714fc5a5db221f63b24c10fc5effd1a7c04c279a9593c9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}